import numpy as np
import sys
sys.path.append('/home/milad/Desktop/Master_Thesis/code/Master_Thesis_Code')
import random
from datasets.embedded_datasets.dataset.embedding_base import EmbeddingBaseDataset as EmbeddingDatabase
import matplotlib.pyplot as plt
import os
from datasets.base_dataset_abstraction import BaseDataset
from configs.global_config import GlobalConfig
from distance_functions.distance_function_metrics.interclass_distance_matrix_metrics import calculate_all_distance_metrics_on_distance_matrix, calculate_n_sample_balanced_distance_matrix,calculate_softmax,standardize_array_mean
from distance_functions.functions.cubical_complex_distance import CubicalComplexImageDistanceFunction
import json

from datasets.dataset_factory import BASE_MODULES as DATA_SET_MODULES

def calculate_distance_function_metrics_on_dataset(database,per_class_samples = 10,distance_fn = None):
    if distance_fn is None:
        distance_fn = euclidean_distance_function
    metrics = {}
    distance_matrix, labels_shuffled, per_class_indicies = calculate_n_sample_balanced_distance_matrix(database,per_class_samples,distance_fn)#needs rework
    
    metrics.update(calculate_all_distance_metrics_on_distance_matrix(distance_matrix, labels_shuffled, per_class_indicies))#needs rework
    #metrics.update(get_embedding_score(database))#silhouette_score, CREATE!
    #path = get_directory_path(database)
    #metrics  = save_score(mean,data_used,path)
    #visualize_interclass_distances(mean,var,database,path, metrics_dict= metrics)
    return metrics

def save_score(mean,data_used,path):
    score_dict =None
    score_serialize = json.dumps(score_dict)
    with open(os.path.join(path,"score.txt"), "w") as file:
        file.write(score_serialize)
    return score_dict


def calculate_origin_dataset_metrics(embedding_database,distance_function = None,flatten = True):
    if distance_function is None:
        distance_function = euclidean_distance_function
    if isinstance(embedding_database,EmbeddingDatabase): 
        emb_descriptor = embedding_database.embedding_descriptor
        og_db = DATA_SET_MODULES.get(emb_descriptor.dataset_name,None)
        database = og_db(training_mode = True,gpu= False,numpy = True,flatten = flatten,balance_dataset_classes = emb_descriptor.dataset_sampling)

    elif isinstance(embedding_database,BaseDataset):
        database = embedding_database   
    else:
        raise TypeError("input needs to be an embedding database or the original dataset itself")
    metrics = calculate_distance_function_metrics_on_dataset(database,distance_fn=distance_function)
    return metrics    


def compute_distance_between_classes(distance_fn,class1,class2=None):
    if class2 is None:
        class2=class1.copy()#SHALLOW COPY
        random.shuffle(class2)
    samples = zip(class1,class2)
    distances= []
    for input_pair in samples:
        distances.append(distance_fn(input_pair))
    mean = np.mean(distances)
    var = np.var(distances)
    return mean,var

def euclidean_distance_function(x):
    assert len(x)==2
    out_dic =np.linalg.norm(x[0] - x[1])
    return out_dic

        

def calculate_interclass_distances(database ,per_class_nb_samples,distance_fn):
    classes  = database.classes
    class_count = len(classes)
    mean_distance_matrix = np.zeros((class_count,class_count))
    var_distance_matrix = np.zeros((class_count,class_count))
    data = database.get_random_instances_from_all_classes(per_class_nb_samples)
    for i in range(class_count):
            for j in range(i, class_count):
                if i != j:
                    mean_distance_matrix[i,j],var_distance_matrix[i,j] =  compute_distance_between_classes(distance_fn,data[classes[i]],data[classes[j]])
                    mean_distance_matrix[j,i],var_distance_matrix[j,i] = mean_distance_matrix[i,j],var_distance_matrix[i,j]
                else:
                    mean_distance_matrix[i,i],var_distance_matrix[i,i]= compute_distance_between_classes(distance_fn,data[classes[i]])
    return mean_distance_matrix,var_distance_matrix,data

def visualize_interclass_distances(mean_distance,variance_of_distance_matrix,database, path,metrics_dict = {}):
    fig, axs = plt.subplots(1, 3, figsize=(20, 10))
    fig.suptitle(f"Interclass Distance generated by {database.name} embedding of {database.data_origin} dataset", fontsize=30)
    normalized_mean = standardize_array_mean(mean_distance)
    normalized_var = standardize_array_mean(variance_of_distance_matrix,per_row_standardization=False)
    soft_max_mean = calculate_softmax(mean_distance,True)
    im0 = axs[0].imshow(soft_max_mean, cmap='viridis')
    axs[0].set_title(f"Prediction Generated by softmax prediction", fontsize=20)
    im1 = axs[1].imshow(normalized_mean, cmap='viridis')
    axs[1].set_title(f"Average Distance", fontsize=20)
    im2 = axs[2].imshow(normalized_var, cmap='viridis')
    axs[2].set_title("Variance of Distance", fontsize=20)

    fig.colorbar(im0, ax=axs[0], fraction=0.046, pad=0.04)
    fig.colorbar(im1, ax=axs[1], fraction=0.046, pad=0.04)
    fig.colorbar(im2, ax=axs[2], fraction=0.046, pad=0.04)

    metrics_text = '    '.join([f'{key}: {value:.2f}' for key, value in metrics_dict.items()])
    plt.gcf().text(0.08, 0.85, metrics_text, fontsize=24, verticalalignment='top')
    save_path = os.path.join(path,"interclass_embedded_distances.png")
    plt.savefig(save_path)
    plt.close(fig)

def get_directory_path(database):
    name = database.name
    if hasattr(database, 'data_origin'):
        data_origin = database.data_origin
    else:
        data_origin = name
        name = "identity_embedding"
    path = os.path.join(GlobalConfig.RESULTS_DATA_FOLDER_PATH,f"{data_origin}_interinstance_distances",GlobalConfig.EMBEDDING_RESULTS,name)
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)
    return path



def visualize_embedding_performance_wrt_dimension(methode_name,metrics,down_dim,data_origin):
    num_metrics = len(metrics[0])
    fig, axs = plt.subplots(num_metrics, 1, figsize=(10, 5 * num_metrics))

    if num_metrics == 1:
        axs = [axs]

    for i, key in enumerate(metrics[0].keys()):
        y_values = [d[key] for d in metrics]
        axs[i].plot(down_dim, y_values, marker='o', linestyle='-', label=key)
        axs[i].set_title(key, fontsize=16)
        axs[i].set_xlabel('Dimension')
        axs[i].set_ylabel(f"{key} Metric")
        axs[i].legend()

    fig.suptitle(f"Metrics Plots for {methode_name}", fontsize=20)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    base_path = os.path.join(GlobalConfig.RESULTS_DATA_FOLDER_PATH,f"{data_origin}_interinstance_distances/","dimensionality_results")
    os.makedirs(base_path,exist_ok=True)
    path = os.path.join(base_path,f"{methode_name}_metrics_plots.png")
    plt.savefig(path)
    plt.close(fig)

# if __name__ == '__main__':
#     original_dataset_name = "MNIST"    
#     down_dim = GlobalConfig.DOWNPROJECTION_TEST_DIMENSIONS
#     order_of_embeddings = GlobalConfig.EMBEDDING_METHODS
#     base_metrics = test_embedding_origin(original_dataset_name)
#     joint_metrics = {"baseline": base_metrics}
#     for method in order_of_embeddings:
#         metrics = []
#         for dim in down_dim:
#             name = f"{method}_{dim}"
#             print(f"started metrics calculation for {name}")
#             data = EmbeddingDatabase(f"data/{original_dataset_name}/embeddings/{name}/")
#             metrics.append(test_embedding(data))
#             print(f"finished calculating metrics {name}")
#         visualize_embedding_performance_wrt_dimension(methode_name=method,metrics= metrics,down_dim=down_dim)
#         joint_metrics[method] = metrics
#     #visualize_all_embeddings_performance_wrt_dimension(joint_metrics,data_origin=original_dataset_name)